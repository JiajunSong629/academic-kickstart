---
title: "Prostate cancer example"
linktitle: "Prostate cancer example"
date: "2020-05-11"
output:
  blogdown::html_page:
    toc: true
menu:
  esl:
    parent: Chapter 3
    weight: 1
type: docs
weight: 1
editor_options: 
  chunk_output_type: console
---


<div id="TOC">
<ul>
<li><a href="#load-library-and-data">Load library and data</a></li>
<li><a href="#duplicate-of-table-3.1">Duplicate of Table 3.1</a></li>
<li><a href="#duplicate-of-table-3.2">Duplicate of Table 3.2</a></li>
<li><a href="#comments">Comments</a></li>
<li><a href="#duplicate-of-figure-3.5">Duplicate of Figure 3.5</a></li>
<li><a href="#duplicate-of-figure-3.7">Duplicate of Figure 3.7</a></li>
</ul>
</div>

<div id="load-library-and-data" class="section level2">
<h2>Load library and data</h2>
<pre class="r"><code>library(tidyverse)
library(knitr)
library(kableExtra)
library(xtable)

prostate_raw &lt;- read.table(here::here(&quot;static&quot;, &quot;data&quot;, &quot;prostate.data&quot;))

# to replicate the results, however would violate the idea
# of train/test split
prostate &lt;- prostate_raw
prostate[, 1:8] &lt;- scale(prostate[, 1:8])
#summary(prostate)</code></pre>
</div>
<div id="duplicate-of-table-3.1" class="section level2">
<h2>Duplicate of Table 3.1</h2>
<pre class="r"><code>Training &lt;- subset(prostate, train)
Testing &lt;- subset(prostate, !train)

p &lt;- 8; nrow &lt;- nrow(Training)

Xtrain &lt;- as.matrix(Training[, 1:p])
ytrain &lt;- as.matrix(Training[, p+1]); colnames(ytrain) &lt;- colnames(Training)[p+1]
Xtest &lt;- as.matrix(Testing[, 1:p])
ytest &lt;- as.matrix(Testing[, p+1]); colnames(ytest) &lt;- colnames(Testing)[p+1]

kable(round(cor(Xtrain), digits=3),
      caption = &quot;Correlation matrix (after global scaling)&quot;)</code></pre>
<table>
<caption>
<span id="tab:unnamed-chunk-2">Table 1: </span>Correlation matrix (after global scaling)
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
lcavol
</th>
<th style="text-align:right;">
lweight
</th>
<th style="text-align:right;">
age
</th>
<th style="text-align:right;">
lbph
</th>
<th style="text-align:right;">
svi
</th>
<th style="text-align:right;">
lcp
</th>
<th style="text-align:right;">
gleason
</th>
<th style="text-align:right;">
pgg45
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
lcavol
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.300
</td>
<td style="text-align:right;">
0.286
</td>
<td style="text-align:right;">
0.063
</td>
<td style="text-align:right;">
0.593
</td>
<td style="text-align:right;">
0.692
</td>
<td style="text-align:right;">
0.426
</td>
<td style="text-align:right;">
0.483
</td>
</tr>
<tr>
<td style="text-align:left;">
lweight
</td>
<td style="text-align:right;">
0.300
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.317
</td>
<td style="text-align:right;">
0.437
</td>
<td style="text-align:right;">
0.181
</td>
<td style="text-align:right;">
0.157
</td>
<td style="text-align:right;">
0.024
</td>
<td style="text-align:right;">
0.074
</td>
</tr>
<tr>
<td style="text-align:left;">
age
</td>
<td style="text-align:right;">
0.286
</td>
<td style="text-align:right;">
0.317
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.287
</td>
<td style="text-align:right;">
0.129
</td>
<td style="text-align:right;">
0.173
</td>
<td style="text-align:right;">
0.366
</td>
<td style="text-align:right;">
0.276
</td>
</tr>
<tr>
<td style="text-align:left;">
lbph
</td>
<td style="text-align:right;">
0.063
</td>
<td style="text-align:right;">
0.437
</td>
<td style="text-align:right;">
0.287
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
-0.139
</td>
<td style="text-align:right;">
-0.089
</td>
<td style="text-align:right;">
0.033
</td>
<td style="text-align:right;">
-0.030
</td>
</tr>
<tr>
<td style="text-align:left;">
svi
</td>
<td style="text-align:right;">
0.593
</td>
<td style="text-align:right;">
0.181
</td>
<td style="text-align:right;">
0.129
</td>
<td style="text-align:right;">
-0.139
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.671
</td>
<td style="text-align:right;">
0.307
</td>
<td style="text-align:right;">
0.481
</td>
</tr>
<tr>
<td style="text-align:left;">
lcp
</td>
<td style="text-align:right;">
0.692
</td>
<td style="text-align:right;">
0.157
</td>
<td style="text-align:right;">
0.173
</td>
<td style="text-align:right;">
-0.089
</td>
<td style="text-align:right;">
0.671
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.476
</td>
<td style="text-align:right;">
0.663
</td>
</tr>
<tr>
<td style="text-align:left;">
gleason
</td>
<td style="text-align:right;">
0.426
</td>
<td style="text-align:right;">
0.024
</td>
<td style="text-align:right;">
0.366
</td>
<td style="text-align:right;">
0.033
</td>
<td style="text-align:right;">
0.307
</td>
<td style="text-align:right;">
0.476
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.757
</td>
</tr>
<tr>
<td style="text-align:left;">
pgg45
</td>
<td style="text-align:right;">
0.483
</td>
<td style="text-align:right;">
0.074
</td>
<td style="text-align:right;">
0.276
</td>
<td style="text-align:right;">
-0.030
</td>
<td style="text-align:right;">
0.481
</td>
<td style="text-align:right;">
0.663
</td>
<td style="text-align:right;">
0.757
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
</tbody>
</table>
</div>
<div id="duplicate-of-table-3.2" class="section level2">
<h2>Duplicate of Table 3.2</h2>
<pre class="r"><code>Xp &lt;- cbind(matrix(1, nrow, 1), Xtrain)
beta_hat &lt;- solve(t(Xp) %*% Xp) %*% t(Xp) %*% ytrain

yfit &lt;- Xp %*% beta_hat
sigma2_hat &lt;- sum((yfit - ytrain)^2) / (nrow - p - 1)
se &lt;- sqrt(sigma2_hat * diag(solve(t(Xp) %*% Xp)))

lm_summary &lt;- data.frame(
  cbind(beta_hat, se, beta_hat/se),
  row.names = c(&quot;Intercept&quot;, names(se)[-1])
)
colnames(lm_summary) &lt;- c(&quot;Coefficient&quot;, &quot;Std. Err&quot;, &quot;Z Score&quot;)

kable(lm_summary, digits = 2,
      caption = &quot;Linear model fit summary&quot;)</code></pre>
<table>
<caption>
<span id="tab:unnamed-chunk-3">Table 2: </span>Linear model fit summary
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Coefficient
</th>
<th style="text-align:right;">
Std. Err
</th>
<th style="text-align:right;">
Z Score
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
2.46
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
27.60
</td>
</tr>
<tr>
<td style="text-align:left;">
lcavol
</td>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
0.13
</td>
<td style="text-align:right;">
5.37
</td>
</tr>
<tr>
<td style="text-align:left;">
lweight
</td>
<td style="text-align:right;">
0.26
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
2.75
</td>
</tr>
<tr>
<td style="text-align:left;">
age
</td>
<td style="text-align:right;">
-0.14
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
-1.40
</td>
</tr>
<tr>
<td style="text-align:left;">
lbph
</td>
<td style="text-align:right;">
0.21
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
2.06
</td>
</tr>
<tr>
<td style="text-align:left;">
svi
</td>
<td style="text-align:right;">
0.31
</td>
<td style="text-align:right;">
0.12
</td>
<td style="text-align:right;">
2.47
</td>
</tr>
<tr>
<td style="text-align:left;">
lcp
</td>
<td style="text-align:right;">
-0.29
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
-1.87
</td>
</tr>
<tr>
<td style="text-align:left;">
gleason
</td>
<td style="text-align:right;">
-0.02
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
-0.15
</td>
</tr>
<tr>
<td style="text-align:left;">
pgg45
</td>
<td style="text-align:right;">
0.27
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
1.74
</td>
</tr>
</tbody>
</table>
</div>
<div id="comments" class="section level2">
<h2>Comments</h2>
<p>F-statistic on non-signifcant terms, <code>age</code>, <code>lcp</code>, <code>gleason</code>, <code>pgg45</code>.</p>
<pre class="r"><code>df &lt;- as.data.frame(cbind(Xtrain, ytrain))

full_lm &lt;- lm(lpsa ~ ., data = df)
sub_lm &lt;- lm(lpsa ~ . -age-lcp-gleason-pgg45, data = df)

full_rss &lt;- sum(full_lm$residuals^2)
sub_rss &lt;- sum(sub_lm$residuals^2)

Fstat &lt;- ((sub_rss - full_rss) / (sub_lm$df - full_lm$df)) / (full_rss / full_lm$df)
pval &lt;- pf(Fstat, df1 = sub_lm$df - full_lm$df, df2 = full_lm$df, lower.tail = F)

ftest &lt;- data.frame(
  matrix(c(Fstat, sub_lm$df-full_lm$df, full_lm$df, pval), nrow = 1)
)

colnames(ftest) &lt;- c(&quot;F-stats&quot;, &quot;df1&quot;, &quot;df2&quot;, &quot;p-value&quot;)

kable(ftest, digits = 2,
      caption = &quot;F-test on nonsignifcant terms&quot;)</code></pre>
<table>
<caption>
<span id="tab:unnamed-chunk-4">Table 3: </span>F-test on nonsignifcant terms
</caption>
<thead>
<tr>
<th style="text-align:right;">
F-stats
</th>
<th style="text-align:right;">
df1
</th>
<th style="text-align:right;">
df2
</th>
<th style="text-align:right;">
p-value
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1.67
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
58
</td>
<td style="text-align:right;">
0.17
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>ypred_test &lt;- predict(full_lm, as.data.frame(Xtest))
mean_pred_err &lt;- mean((ypred_test - as.matrix(ytest))^2)
base_err &lt;- mean((as.matrix(ytest) - mean(ytrain))^2)

data.frame(matrix(c(mean_pred_err, base_err), nrow = 1)) %&gt;%
  `colnames&lt;-`(c(&quot;Mean prediction error&quot;, &quot;Base error&quot;)) %&gt;%
  kable(digits = 2, caption = &quot;Linear fit reduces the error by 50%&quot;)</code></pre>
<table>
<caption>
<span id="tab:unnamed-chunk-5">Table 4: </span>Linear fit reduces the error by 50%
</caption>
<thead>
<tr>
<th style="text-align:right;">
Mean prediction error
</th>
<th style="text-align:right;">
Base error
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.52
</td>
<td style="text-align:right;">
1.06
</td>
</tr>
</tbody>
</table>
</div>
<div id="duplicate-of-figure-3.5" class="section level2">
<h2>Duplicate of Figure 3.5</h2>
<pre class="r"><code># get k = 0 (no features) model
obj &lt;- lm(lpsa ~ +1, data=df)
xPlot &lt;- c(0); yPlot &lt;- c(sum(obj$residual^2))

for (k in 1:p) {
  allPosSubsetsSizeK = combn(p,k)
  numOfSubsets = dim(allPosSubsetsSizeK)[2]
  
  for (si in 1:numOfSubsets) {
    featIndices = allPosSubsetsSizeK[, si]
    featNames = as.vector(names(df))[featIndices]
    
    formula = &quot;lpsa ~&quot;
    for (ki in 1:k) {
      if (ki == 1) {
        formula = paste(formula, featNames[ki], sep = &quot; &quot;)
      } else {
        formula = paste(formula, featNames[ki], sep = &quot;+&quot;)
      }
    }
    
    obj &lt;- lm(formula, data = df)
    xPlot &lt;- c(xPlot, k); yPlot &lt;- c(yPlot, sum(obj$residuals^2))
  }
}

xMinPlot = xPlot[1]; yMinPlot = yPlot[1]
for (ki in 1:p) {
  rssmin = min(yPlot[xPlot == ki])
  xMinPlot = c(xMinPlot, ki)
  yMinPlot = c(yMinPlot, rssmin)
}

ggplot() +
  geom_point(aes(x = xPlot, y = yPlot), color = &quot;gray50&quot;) +
  geom_point(aes(x = xMinPlot, y = yMinPlot), color = &quot;red&quot;, size = 2) +
  geom_line(aes(x = xMinPlot, y = yMinPlot), color = &quot;red&quot;) +
  scale_x_continuous(breaks = 0:8) +
  #scale_y_continuous(breaks = seq(0, 100, 20)) +
  lims(y = c(-5, 100)) +
  labs(x = &quot;Subset size k&quot;, y = &quot;Residual Sum-of-Squares&quot;) +
  theme_classic()</code></pre>
<p><img src="/courses/ESL/prostate_cancer_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="duplicate-of-figure-3.7" class="section level2">
<h2>Duplicate of Figure 3.7</h2>
<pre class="r"><code># cross-validation helper function
cv_all_subsets &lt;- function(k, df, numberOfCV=10) {
  nSamples = dim(df)[1]; p = dim(df)[2]-1
  responseName = names(df)[p+1]
  
  if (k == 0) {
    form = paste(responseName, &quot;~ +1&quot;)
    bestErrors = cvLM(form, df, numberOfCV)
    bestFeaturesIndices = NULL
    bestFormula = form
  } else {
    allPosSubsetsSizeK = combn(p, k)
    numOfSubsets = dim(allPosSubsetsSizeK)[2]
    
    for (si in 1:numOfSubsets) {
      featuresIndices = allPosSubsetsSizeK[, si]
      featuresNames = as.vector(names(df))[featuresIndices]
      
      form = paste(responseName, &quot; ~ &quot;)
      for (ki in 1:k) {
        if (ki == 1) {
          form = paste(form, featuresNames[ki], sep = &quot; &quot;)
        } else {
          form = paste(form, featuresNames[ki], sep = &quot;+&quot;)
        }
      }
      
      expectedPredictionErrors = cvLM(form, df, numberOfCV)
      
      if (si == 1) {
        bestErrors = expectedPredictionErrors
        bestFeaturesIndices = featuresIndices
        bestFormula = form
      } else {
        if (mean(expectedPredictionErrors) &lt; mean(bestErrors)) {
          bestErrors = expectedPredictionErrors
          bestFeaturesIndices = featuresIndices
          bestFormula = form
        }
      }
    }
  }
  
  res = list(bestErrors, bestFeaturesIndices, bestFormula)
  return (res)
}</code></pre>
<pre class="r"><code>cvLM &lt;- function(form, df, numberOfCV=10) {
  nSamples = dim(df)[1]; p = dim(df)[2]-1
  nCVTest = round(nSamples / numberOfCV)
  
  # test and train indices
  for (cvi in 1:numberOfCV) {
    testinds = (cvi-1)*nCVTest + 1:nCVTest
    testinds = intersect(testinds, 1:nSamples)
    traininds = setdiff(1:nSamples, testinds)
    
    dcv = df[traininds, ]
    obj &lt;- lm(formula = form, data = dcv)
    ypred_test &lt;- predict(obj, newdata = df[testinds, 1:p], interval = &quot;prediction&quot;)[, 1]
    response &lt;- df[testinds, p+1]
    
    if (cvi == 1) {
      ypred = c(ypred_test)
      y = c(response)
    } else{
      ypred = c(ypred, ypred_test)
      y = c(y, response)
    }
  }
  
  return ((ypred - y)^2)
}</code></pre>
<pre class="r"><code># All subsets
for (k in 0:p) {
  res = cv_all_subsets(k, df, numberOfCV = 10)
  
  if (k == 0) {
    complexityParam = c(k)
    cvResults = res[[1]]
    bestFormula = res[[3]]
  } else {
    complexityParam = c(complexityParam, k)
    cvResults = cbind(cvResults, res[[1]])
    bestFormula = c(bestFormula, res[[3]])
  }
}

cvResults &lt;- data.frame(cvResults) %&gt;%
  `colnames&lt;-`(paste0(&quot;subset&quot;, 0:8))

cvErrors &lt;- apply(cvResults, 2, mean)
cvSd &lt;- sqrt( apply(cvResults,2,var)/dim(cvResults)[1] ) 

ggplot() +
  geom_errorbar(aes(x = 0:8, y = cvErrors, ymin = cvErrors-cvSd, ymax = cvErrors+cvSd),
                  color = &quot;#70B4E0&quot;, width = 0.2) +
  geom_line(aes(x = 0:8, y = cvErrors), color = &quot;#D6B62A&quot;) +
  geom_point(aes(x = 0:8, y = cvErrors), color = &quot;#D6B62A&quot;) +
  scale_y_continuous(breaks = seq(0.6, 1.8, 0.2)) +
  labs(x = &quot;Subset size&quot;, y = &quot;CV Error&quot;) +
  theme_classic()</code></pre>
<p><img src="/courses/ESL/prostate_cancer_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>#lm(bestFormula[3], data=df)$coef</code></pre>
</div>
